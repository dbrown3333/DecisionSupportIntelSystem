{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\d brown\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\d brown\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\d brown\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\d brown\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\d brown\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\d brown\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 51.000000 percent accurate\n",
      "KNN is 69.000000 percent accurate\n",
      "Naive Bayes is 27.000000 percent accurate\n",
      "Linear SVMs is 49.000000 percent accurate\n",
      "Non Linear SVMs is 52.000000 percent accurate\n",
      "Decision Trees is 67.000000 percent accurate\n",
      "Random Forests is 66.000000 percent accurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49]\n",
      "K-Fold Score: 0.442\n",
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6]\n",
      "K-Fold Score: 0.5319999999999999\n",
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53]\n",
      "K-Fold Score: 0.4873333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57]\n",
      "K-Fold Score: 0.472\n",
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66]\n",
      "K-Fold Score: 0.5064\n",
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66, 0.62, 0.71, 0.65, 0.64, 0.63]\n",
      "K-Fold Score: 0.5303333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66, 0.62, 0.71, 0.65, 0.64, 0.63, 0.71, 0.62, 0.61, 0.64, 0.67]\n",
      "Stratified K-Fold Score: 0.5474285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66, 0.62, 0.71, 0.65, 0.64, 0.63, 0.71, 0.62, 0.61, 0.64, 0.67, 0.48, 0.36, 0.49, 0.43, 0.46]\n",
      "Stratified K-Fold Score: 0.5345\n",
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66, 0.62, 0.71, 0.65, 0.64, 0.63, 0.71, 0.62, 0.61, 0.64, 0.67, 0.48, 0.36, 0.49, 0.43, 0.46, 0.62, 0.68, 0.65, 0.6, 0.57]\n",
      "Stratified K-Fold Score: 0.5444444444444444\n",
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66, 0.62, 0.71, 0.65, 0.64, 0.63, 0.71, 0.62, 0.61, 0.64, 0.67, 0.48, 0.36, 0.49, 0.43, 0.46, 0.62, 0.68, 0.65, 0.6, 0.57, 0.42, 0.43, 0.43, 0.41, 0.48]\n",
      "Stratified K-Fold Score: 0.5334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66, 0.62, 0.71, 0.65, 0.64, 0.63, 0.71, 0.62, 0.61, 0.64, 0.67, 0.48, 0.36, 0.49, 0.43, 0.46, 0.62, 0.68, 0.65, 0.6, 0.57, 0.42, 0.43, 0.43, 0.41, 0.48, 0.23, 0.4, 0.21, 0.16, 0.27]\n",
      "Stratified K-Fold Score: 0.508\n",
      "Accuracy score in each iteration: [0.41, 0.45, 0.42, 0.44, 0.49, 0.6, 0.62, 0.7, 0.59, 0.6, 0.5, 0.24, 0.42, 0.3, 0.53, 0.41, 0.46, 0.28, 0.41, 0.57, 0.64, 0.64, 0.68, 0.6, 0.66, 0.62, 0.71, 0.65, 0.64, 0.63, 0.71, 0.62, 0.61, 0.64, 0.67, 0.48, 0.36, 0.49, 0.43, 0.46, 0.62, 0.68, 0.65, 0.6, 0.57, 0.42, 0.43, 0.43, 0.41, 0.48, 0.23, 0.4, 0.21, 0.16, 0.27, 0.66, 0.64, 0.72, 0.62, 0.62]\n",
      "Stratified K-Fold Score: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\D Brown\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "hospitalCost=pd.read_csv('HospitalDataset/HospitalCosts.csv')\n",
    "hospitalCost\n",
    "hospitalCost.shape\n",
    "hospitalCost.columns\n",
    "!pip install numpy\n",
    "import numpy as np\n",
    "hospitalCost.select_dtypes(np.number)\n",
    "hospitalCost[hospitalCost['RACE'].isnull()]\n",
    "hospitalCost=hospitalCost.drop(labels=276, axis=0)\n",
    "X = hospitalCost.drop(['LOS'], axis=1)\n",
    "Y = hospitalCost['LOS']\n",
    "X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "seed=0\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=2, shuffle=True)\n",
    "def return_score(model,X_train, X_test, y_train, y_test):\n",
    "   model.fit(X_train, y_train)\n",
    "   score = model.score(X_test, y_test)\n",
    "   return score\n",
    "scores = []\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"K-Fold Score: {}\".format(np.mean(scores)))\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5,random_state=2, shuffle=True)\n",
    "model = RandomForestClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = LogisticRegression()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = KNeighborsClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = GaussianNB()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = LinearSVC()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))\n",
    "model = DecisionTreeClassifier()\n",
    "for train_index, test_index in cv.split(X,Y):\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)\n",
    "   score = return_score(model,X_train, X_test, y_train, y_test)   \n",
    "   scores.append(score)\n",
    "print(\"Accuracy score in each iteration: {}\".format(scores))\n",
    "print(\"Stratified K-Fold Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
